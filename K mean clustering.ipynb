{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review\n",
      "0                                   open app anymore\n",
      "1           begging refund app month nobody replying\n",
      "2  costly premium version approx Indian Rupees pe...\n",
      "3  Used keep organized UPDATES made mess things c...\n",
      "4                                   Dan Birthday Oct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   category     term   frequency\n",
      "0         0      app  189.611081\n",
      "1         1    tasks   58.099738\n",
      "2         2     work   48.774678\n",
      "3         3     good   37.940386\n",
      "4         4  version   69.153458\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "# Download necessary files from NLTK:\n",
    "# punkt -> Tokenization\n",
    "# stopwords -> Stop words removal\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "# Load the file dataset and preview it\n",
    "file = pd.read_csv(\"reviews.csv\")\n",
    "file.head()\n",
    "# Filter negative file (score of 1 or 2)\n",
    "neg__file = file[(file[\"score\"] == 1) | (file[\"score\"] == 2)][\"content\"]\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Performs tokenization, stop word removal, and non-alpha character removal.\"\"\"\n",
    "    tokens = word_tokenize(text)\n",
    "    filtered_tokens = [\n",
    "        token for token in tokens if token.isalpha() and token.lower() not in stopwords.words(\"english\")\n",
    "    ]\n",
    "    return \" \".join(filtered_tokens)\n",
    "\n",
    "# Apply the preprocessing function to the negative file\n",
    "neg__file_cleaned = neg__file.apply(preprocess_text)\n",
    "\n",
    "# Store the preprocessed file in a DataFrame\n",
    "preprocessed_file = pd.DataFrame({\"review\": neg__file_cleaned})\n",
    "print(preprocessed_file.head())\n",
    "\n",
    "\n",
    "# Vectorize the cleaned file using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(preprocessed_file[\"review\"])\n",
    "\n",
    "\n",
    "# Apply K-means clustering\n",
    "clust_kmeans = KMeans(n_clusters=5, random_state=500)\n",
    "pred_labels = clust_kmeans.fit_predict(tfidf_matrix)\n",
    "\n",
    "# Store the predicted labels in a list\n",
    "categories = pred_labels.tolist()\n",
    "preprocessed_file[\"category\"] = categories\n",
    "\n",
    "\n",
    "# Get the feature names (terms) from the vectorizer\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "\n",
    "# List to save the top term for each cluster\n",
    "topic_terms_list = []\n",
    "\n",
    "for cluster in range(clust_kmeans.n_clusters):\n",
    "    # Get indices of file in the current cluster\n",
    "    cluster_indices = [i for i, label in enumerate(categories) if label == cluster]\n",
    "\n",
    "    # Sum the TF-IDF scores for each term in the cluster\n",
    "    cluster_tfidf_sum = tfidf_matrix[cluster_indices].sum(axis=0)\n",
    "    cluster_term_freq = np.asarray(cluster_tfidf_sum).ravel()\n",
    "\n",
    "    # Get the top term and its frequency\n",
    "    top_term_index = cluster_term_freq.argsort()[::-1][0]\n",
    "    top_term = terms[top_term_index]\n",
    "    top_term_frequency = cluster_term_freq[top_term_index]\n",
    "\n",
    "    # Append the results to the list\n",
    "    topic_terms_list.append({\n",
    "        \"category\": cluster,\n",
    "        \"term\": top_term,\n",
    "        \"frequency\": top_term_frequency\n",
    "    })\n",
    "\n",
    "# Store the results in a DataFrame\n",
    "topic_terms = pd.DataFrame(topic_terms_list)\n",
    "print(topic_terms)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
