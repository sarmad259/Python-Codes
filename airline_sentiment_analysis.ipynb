{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.015262414707312258\n",
      "Epoch: 2, Loss: 0.013305138553788964\n",
      "Epoch: 3, Loss: 0.010755963787520091\n",
      "Accuracy: 0.1749730312837109\n",
      "Precision (per class): [0.73333333 0.         0.13846154 0.18181818 0.36842105 0.\n",
      " 0.         0.         0.         0.4        0.         0.26666667\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.35483871 0.         0.         0.5        0.\n",
      " 0.         0.         0.         0.26666667 0.         0.\n",
      " 0.         0.         0.         0.         0.66666667 0.\n",
      " 0.17647059 0.         0.         0.         0.         0.0862069\n",
      " 0.         0.         0.81818182 0.64285714 0.         0.\n",
      " 0.         0.25       0.25       0.         0.         0.\n",
      " 0.         0.07228916 0.17647059 0.90909091 0.         0.33333333\n",
      " 0.         0.0952381  0.05813953 0.         1.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.47368421 0.08333333 0.         0.         0.         0.07936508\n",
      " 0.15384615 0.         0.         0.         0.         0.\n",
      " 0.26190476 0.         0.         0.0875     0.         0.\n",
      " 0.         0.07692308 0.         0.         0.         0.\n",
      " 0.06293706 0.10638298 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.4375     0.         0.53333333 0.         1.\n",
      " 0.         0.         0.         0.         0.14285714 0.\n",
      " 0.         0.38461538 0.         0.         0.         0.\n",
      " 0.         0.         0.25       0.76923077 0.         0.\n",
      " 0.06410256 0.         0.5        1.         0.         0.\n",
      " 0.         0.08208955 0.27272727 0.         0.         0.\n",
      " 0.30434783 0.         0.66666667 0.07936508 0.         0.\n",
      " 0.0625     0.07142857 0.         0.4        0.         0.\n",
      " 0.52631579 0.75       0.         0.         0.         0.7\n",
      " 0.625      0.16438356 0.83333333 0.         0.         0.\n",
      " 0.         0.         0.29411765 0.         0.         0.19148936\n",
      " 0.02272727 0.1        0.         0.875      0.         0.\n",
      " 0.5        0.         0.46153846 0.         0.         0.\n",
      " 0.23684211 0.         0.         0.7        0.         0.5\n",
      " 0.1        0.         0.35714286 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.14754098 0.14285714\n",
      " 0.29411765 0.         0.         0.         0.         0.15384615\n",
      " 0.         0.         0.         0.         0.5        1.\n",
      " 0.175      0.         0.1        0.5        0.         0.\n",
      " 0.         0.         0.         0.         0.5        0.\n",
      " 0.14285714 0.         0.         0.         0.6        0.36363636\n",
      " 0.         0.         0.07142857 0.         0.42307692 0.\n",
      " 0.         0.         0.21428571 0.         0.         0.\n",
      " 0.18604651 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.2295082  0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.12903226 0.2        0.         0.         0.         0.\n",
      " 0.         0.         0.05714286 0.25       0.01785714 0.\n",
      " 0.         1.         0.         0.         0.38461538 0.04545455\n",
      " 0.         0.         0.         0.         0.03773585 0.\n",
      " 0.         1.         0.94117647 0.5        1.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.47058824 0.         0.         0.         0.25\n",
      " 0.         0.         0.5        0.         0.08108108 0.\n",
      " 0.         0.         0.         0.         0.21875    0.\n",
      " 0.         0.20754717 0.5        0.25       0.83333333 0.\n",
      " 0.         0.3        0.24444444 0.         0.         0.55555556\n",
      " 0.         0.         1.         0.         0.57692308 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.09375    0.1        0.01631321 0.\n",
      " 0.         0.         0.         0.33333333 0.         0.\n",
      " 0.         0.         0.05633803 0.         0.21875    0.\n",
      " 0.         0.         0.         0.         0.07692308 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.625      0.33333333 0.         0.25641026 0.         0.5\n",
      " 0.         1.         0.5        0.33333333 0.62068966 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.42857143 0.9        0.         0.         0.         0.5\n",
      " 0.05263158 0.16666667 0.         0.         0.         0.        ]\n",
      "Recall (per class): [0.52380952 0.         0.6        0.11764706 0.63636364 0.\n",
      " 0.         0.         0.         0.36363636 0.         0.23529412\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.61111111 0.         0.         0.1875     0.\n",
      " 0.         0.         0.         0.2        0.         0.\n",
      " 0.         0.         0.         0.         0.0952381  0.\n",
      " 0.27272727 0.         0.         0.         0.         0.45454545\n",
      " 0.         0.         0.52941176 0.39130435 0.         0.\n",
      " 0.         0.75       0.36363636 0.         0.         0.\n",
      " 0.         0.3        0.13636364 0.43478261 0.         0.75\n",
      " 0.         0.23529412 0.26315789 0.         0.04761905 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.33333333 0.24       0.         0.         0.         0.38461538\n",
      " 0.11764706 0.         0.         0.         0.         0.\n",
      " 0.44       0.         0.         0.33333333 0.         0.\n",
      " 0.         0.0625     0.         0.         0.         0.\n",
      " 0.45       0.3125     0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.38888889 0.         0.44444444 0.         0.45\n",
      " 0.         0.         0.         0.         0.2        0.\n",
      " 0.         0.35714286 0.         0.         0.         0.\n",
      " 0.         0.         0.31578947 0.38461538 0.         0.\n",
      " 0.2        0.         0.09090909 0.04761905 0.         0.\n",
      " 0.         0.55       0.81818182 0.         0.         0.\n",
      " 0.60869565 0.         0.31578947 1.         0.         0.\n",
      " 0.04545455 0.0952381  0.         0.1        0.         0.\n",
      " 0.5        0.13636364 0.         0.         0.         0.66666667\n",
      " 0.45454545 0.63157895 0.43478261 0.         0.         0.\n",
      " 0.         0.         0.22727273 0.         0.         0.5\n",
      " 0.18181818 0.05882353 0.         0.36842105 0.         0.\n",
      " 0.04761905 0.         0.5        0.         0.         0.\n",
      " 0.64285714 0.         0.         0.4375     0.         0.64705882\n",
      " 0.2        0.         0.22727273 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.33333333 0.0952381\n",
      " 0.23809524 0.         0.         0.         0.         0.19047619\n",
      " 0.         0.         0.         0.         0.16666667 0.125\n",
      " 0.31818182 0.         0.66666667 0.2        0.         0.\n",
      " 0.         0.         0.         0.         0.1        0.\n",
      " 0.11111111 0.         0.         0.         0.8        0.30769231\n",
      " 0.         0.         0.04761905 0.         0.40740741 0.\n",
      " 0.         0.         0.22222222 0.         0.         0.\n",
      " 0.66666667 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.5        0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.42105263 0.125      0.         0.         0.         0.\n",
      " 0.         0.         0.08       0.25       0.04545455 0.\n",
      " 0.         0.13043478 0.         0.         0.33333333 0.08\n",
      " 0.         0.         0.         0.         0.1        0.\n",
      " 0.         0.29411765 0.88888889 0.31578947 0.11538462 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.47058824 0.         0.         0.         0.5\n",
      " 0.         0.         0.42105263 0.         0.15789474 0.\n",
      " 0.         0.         0.         0.         0.63636364 0.\n",
      " 0.         0.55       0.26315789 0.1875     0.23809524 0.\n",
      " 0.         0.33333333 0.52380952 0.         0.         0.3125\n",
      " 0.         0.         0.38461538 0.         0.75       0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.15789474 0.17241379 0.625      0.\n",
      " 0.         0.         0.         0.125      0.         0.\n",
      " 0.         0.         0.25       0.         0.53846154 0.\n",
      " 0.         0.         0.         0.         0.07142857 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.19230769 0.47619048 0.         0.45454545 0.         0.15\n",
      " 0.         0.15789474 0.11111111 0.1        0.85714286 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.31578947 0.52941176 0.         0.         0.         0.04545455\n",
      " 0.375      0.09090909 0.         0.         0.         0.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the dataset (use your path)\n",
    "file_path = 'reveiw.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Preprocess the dataset\n",
    "df = df[['Review', 'Airline Name']].dropna()\n",
    "\n",
    "# Encode the target labels\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['Airline Name'])\n",
    "\n",
    "# Split into train and test sets\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(df['Review'], df['label'], test_size=0.2)\n",
    "\n",
    "# Simple word tokenization and conversion to index (mocking word2idx)\n",
    "word2idx = {word: i+1 for i, word in enumerate(set(\" \".join(train_texts).split()))}\n",
    "vocab_size = len(word2idx) + 1\n",
    "\n",
    "def text_to_tensor(text, max_len):\n",
    "    tensor = torch.tensor([word2idx.get(word, 0) for word in text.split()])\n",
    "    # Padding the tensor to the max length\n",
    "    if len(tensor) < max_len:\n",
    "        padding = torch.zeros(max_len - len(tensor), dtype=torch.long)\n",
    "        tensor = torch.cat((tensor, padding), dim=0)\n",
    "    return tensor[:max_len]  # Truncate if necessary\n",
    "\n",
    "# Determine the maximum sequence length\n",
    "max_len = max(len(text.split()) for text in train_texts)\n",
    "\n",
    "train_data = torch.stack([text_to_tensor(text, max_len) for text in train_texts])\n",
    "test_data = torch.stack([text_to_tensor(text, max_len) for text in test_texts])\n",
    "# Ensure the labels are of type Long\n",
    "train_labels = torch.tensor(train_labels.values, dtype=torch.long)\n",
    "test_labels = torch.tensor(test_labels.values, dtype=torch.long)\n",
    "\n",
    "# Create DataLoader instances\n",
    "batch_size = 400\n",
    "train_loader = DataLoader(TensorDataset(train_data, train_labels), shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(TensorDataset(test_data, test_labels), shuffle=False, batch_size=batch_size)\n",
    "\n",
    "\n",
    "# Define the classifier class\n",
    "class TicketClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, target_size):\n",
    "        super(TicketClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.conv = nn.Conv1d(embed_dim, embed_dim, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc = nn.Linear(embed_dim, target_size)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text).permute(0, 2, 1)\n",
    "        conved = F.relu(self.conv(embedded))\n",
    "        conved = conved.mean(dim=2) \n",
    "        return self.fc(conved)\n",
    "\n",
    "# Set parameters\n",
    "embedding_dim = 64\n",
    "target_size = len(label_encoder.classes_)\n",
    "\n",
    "# Create an instance of the TicketClassifier class\n",
    "model = TicketClassifier(vocab_size, embedding_dim, target_size)\n",
    "\n",
    "lr = 0.05\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# Train the model\n",
    "model.train()\n",
    "epochs = 3\n",
    "for i in range(epochs):\n",
    "    running_loss, num_processed = 0, 0\n",
    "    for inputs, labels in train_loader:\n",
    "        model.zero_grad()\n",
    "        output = model(inputs)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        num_processed += len(inputs)\n",
    "    print(f\"Epoch: {i+1}, Loss: {running_loss/num_processed}\")\n",
    "\n",
    "# Evaluate model on test set\n",
    "model.eval()\n",
    "predicted = []\n",
    "actual = []\n",
    "\n",
    "for inputs, labels in test_loader:\n",
    "    output = model(inputs)\n",
    "    cat = torch.argmax(output, dim=-1)\n",
    "    predicted.extend(cat.tolist())\n",
    "    actual.extend(labels.tolist())\n",
    "\n",
    "# Compute metrics using sklearn\n",
    "accuracy = accuracy_score(actual, predicted)\n",
    "precision = precision_score(actual, predicted, average=None)\n",
    "recall = recall_score(actual, predicted, average=None)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "print('Precision (per class):', precision)\n",
    "print('Recall (per class):', recall)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
